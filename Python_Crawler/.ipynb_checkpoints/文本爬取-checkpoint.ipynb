{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/pic_2.png\" width=\"500\" align=\"bottom\" />\n",
    "\n",
    "#### requests 中文文档:<br />https://requests.readthedocs.io/zh_CN/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    target = 'http://gitbook.cn'\n",
    "    req = requests.get(url=target)\n",
    "    print(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import requests\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    target = 'https://read.qidian.com/chapter/HEqJaV0SQcMj8FaDXua-rg2/eSlFKP1Chzg1'\n",
    "    req = requests.get(url=target)\n",
    "    print(req.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    target = 'http://www.quanben.io/n/jijiabubing/1.html'\n",
    "    req = requests.get(url=target)\n",
    "    html = req.text\n",
    "    bf = BeautifulSoup(html)\n",
    "    #texts = bf.find_all('div',{'id':'content'})\n",
    "    texts = bf.find_all('div')\n",
    "\n",
    "    '''\n",
    "    find_all()\n",
    "    第一个参数是获取的标签名; div是Html中的一种标签\n",
    "    第二个参数class_是标签的属性; class是标签div的属性\n",
    "    '''\n",
    "    print(type(texts))\n",
    "    print(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"/\">首页</a>\n",
      "<class 'bs4.element.Tag'>\n",
      "首页 http://www.quanben.io/n/jijiabubing//\n",
      "<a href=\"/c/kehuan.html\">科幻小说</a>\n",
      "<class 'bs4.element.Tag'>\n",
      "科幻小说 http://www.quanben.io/n/jijiabubing//c/kehuan.html\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "if __name__ == '__main__':\n",
    "    server = 'http://www.quanben.io/n/jijiabubing/'\n",
    "    target = 'http://www.quanben.io/n/jijiabubing/list.html'\n",
    "    req = requests.get(url=target)\n",
    "    html_str = req.text\n",
    "    bf = BeautifulSoup(html_str)\n",
    "    a_href_list = list(bf.find_all('a'))\n",
    "    for a_href in a_href_list[:2]:\n",
    "        print(a_href)\n",
    "        print(type(a_herf))\n",
    "        html_page = a_href.get('href')\n",
    "        html_name = a_href.text\n",
    "        print(html_name,server + html_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('D:\\\\local_github\\\\notebook', 'D:\\\\local_github\\\\notebook\\\\Python_Crawler')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def path_get():\n",
    "    # 当前文件目录\n",
    "    current_path = os.path.abspath('')\n",
    "    # 当前文件夹父目录\n",
    "    father_path = os.path.abspath(os.path.dirname(current_path))\n",
    "    # corpus_path = os.path.join(father_path, corpus)\n",
    "    return father_path, current_path\n",
    "\n",
    "print(path_get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<meta content=\"机甲步兵,云翼,机甲步兵免费阅读\" name=\"keywords\"/>]\n",
      "<class 'bs4.element.Tag'>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import requests\n",
    "from bs4 import BeautifulStoneSoup \n",
    "\n",
    "#获取当前路径\n",
    "current_path = os.path.abspath('')\n",
    "'''\n",
    "继承自 object 是为了使属性(properties)正常工作, \n",
    "并且这样可以保护你的代码, 使其不受 PEP-3000 的一个特殊的潜在不兼容性影响. \n",
    "这样做也定义了一些特殊的方法, \n",
    "这些方法实现了对象的默认语义, 包括:\n",
    "__new__, __init__, __delattr__, __getattribute__，等\n",
    "'''\n",
    "class TextClawer(object):\n",
    "    \n",
    "    def __init__(self, domain_name):\n",
    "        self.domain_name = domain_name\n",
    "        \n",
    "    def get_html_text(self):\n",
    "        req = requests.get(url=self.domain_name)\n",
    "        return req.text\n",
    "    \n",
    "    def find_all_tag_parse_html_text(self, html_text, tag, property_dict={}):\n",
    "        '''\n",
    "        1.查找标签 soup.find_all('tag')\n",
    "        2.查找文本 soup.find_all(text='text')\n",
    "        3.根据id查找 soup.find_all(id='tag id')\n",
    "        4.使用正则 soup.find_all(text=re.compile('your re')), soup.find_all(id=re.compile('your re'))\n",
    "        5.指定属性查找标签 soup.find_all('tag', {'id': 'tag id', 'class': 'tag class'})\n",
    "        '''\n",
    "        bf = BeautifulSoup(html_text)\n",
    "        \n",
    "        parse_result = bf.find_all(tag, property_dict)\n",
    "        \n",
    "        return parse_result\n",
    "    \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    domain_name = 'http://www.quanben.io/n/jijiabubing/'\n",
    "    my_clawer = TextClawer(domain_name)\n",
    "    html_text = my_clawer.get_html_text()\n",
    "    tag = 'meta'\n",
    "    property_dict = {'name':'keywords'}\n",
    "    parse = my_clawer.find_all_tag_parse_html_text(html_text, tag, property_dict)\n",
    "    print(parse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

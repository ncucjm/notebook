{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import math\n",
    "#from New_word_find import New_word\n",
    "\n",
    "\"\"\"\n",
    "a.file_name:输入文件名,一行一个文本\n",
    "b.out_file:输出文件名：segment idf\n",
    "c.out_file:路径与file_name路径一致\n",
    "\"\"\"\n",
    "\n",
    "class Key_word_exact():\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__corpus_file_name = None\n",
    "        self.__idf_file_name = None\n",
    "        self.__stop_word_file_name = None\n",
    "        self.__special_list = []\n",
    "        self.__exact = None\n",
    "        self.__topK = 0\n",
    "        self.__num = 10000\n",
    "        self.__percentage = 100\n",
    "\n",
    "    def set_corpus_file_name(self, corpus_file_name):\n",
    "        assert isinstance(corpus_file_name, str)\n",
    "        self.__corpus_file_name = corpus_file_name\n",
    "\n",
    "    def set_idf_file_name(self, idf_file_name):\n",
    "        assert isinstance(idf_file_name, str)\n",
    "        self.__idf_file_name = idf_file_name\n",
    "\n",
    "    def set_stop_word_file_name(self, stop_word_file_name):\n",
    "        assert isinstance(stop_word_file_name, str)\n",
    "        self.__stop_word_file_name = stop_word_file_name\n",
    "\n",
    "    def set_special_list(self, special_list=['\\n']):\n",
    "        assert isinstance(special_list, list)\n",
    "        self.__special_list = special_list\n",
    "\n",
    "    def set_exact(self, exact='tfidf'):\n",
    "        assert isinstance(exact, str) and \\\n",
    "               (exact == 'tfidf' or exact == 'textrank' or exact =='tf' )\n",
    "        self.__exact = exact\n",
    "\n",
    "    def set_topK(self, topK=10):\n",
    "        assert isinstance(topK, int) and topK > 0\n",
    "        self.__topK = topK\n",
    "\n",
    "    def set_num(self, num=10000):\n",
    "        assert isinstance(num, int)\n",
    "        self.__num = num\n",
    "\n",
    "    def set_percentage(self, percentage=100):\n",
    "        assert isinstance(percentage, int) and (percentage >= 0 and percentage <= 100)\n",
    "        self.__percentage = percentage\n",
    "\n",
    "    \"\"\"\n",
    "    a.待挖掘语料库格式：一行一个文本\n",
    "    b.关键词挖掘：tfidf,textrank,tf模式,返回一个list,元素是挖掘出的关键词\n",
    "    c.tfidf,textrank 单个文本挖掘关键词数量top_K\n",
    "    d.tf 整个挖掘对象返回按tf值大小的关键词数top_K\n",
    "    \"\"\"\n",
    "    def word_exact(self):\n",
    "        current_path = os.path.abspath(__file__)\n",
    "        # 获取当前文件的父目录\n",
    "        father_path = os.path.abspath(os.path.dirname(current_path) + os.path.sep + \".\")\n",
    "        # 获取文件绝对路径\n",
    "        corpus_path = father_path + '\\\\' + self.__corpus_file_name\n",
    "        idf_path = father_path + '\\\\' + self.__idf_file_name\n",
    "        stop_word_path = father_path + '\\\\' + self.__stop_word_file_name\n",
    "\n",
    "        # 语料库文本的idf值\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as file:\n",
    "            corpus_scale = 0\n",
    "            count_dict = {}\n",
    "            for text in file.readlines():\n",
    "                corpus_scale += 1\n",
    "                text_set = set([segment for segment in jieba.cut(text)])\n",
    "                for segment in text_set:\n",
    "                    # 特殊符号去除列表\n",
    "                    if segment not in self.__special_list:\n",
    "                        if segment in count_dict.keys():\n",
    "                            count_dict[segment] += 1\n",
    "                        else:\n",
    "                            count_dict[segment] = 1\n",
    "\n",
    "        with open(idf_path, 'w', encoding='utf-8') as file:\n",
    "            for segment in count_dict.keys():\n",
    "                segment_idf = str(math.log((corpus_scale/(count_dict[segment] + 1))))\n",
    "                out_text = segment + ' ' + segment_idf + '\\n'\n",
    "                file.write(out_text)\n",
    "\n",
    "        # 加载语料空间的idf词典\n",
    "        if self.__idf_file_name:\n",
    "            jieba.analyse.set_idf_path(idf_path)\n",
    "        # 加载停用词词典\n",
    "        if self.__stop_word_file_name:\n",
    "            jieba.analyse.set_stop_words(stop_word_path)\n",
    "\n",
    "        # 对语料库进行关键词挖掘\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as file:\n",
    "            all_key_word = []\n",
    "            # tfiff 方法挖掘,每个文本返回最多top_K个结果\n",
    "            if self.__exact == 'tfidf':\n",
    "                for content in file.readlines()[:self.__num]:\n",
    "                    tags = jieba.analyse.extract_tags(content, topK=self.__topK)\n",
    "\n",
    "                    for keyword in tags:\n",
    "                        if keyword not in all_key_word:\n",
    "                            all_key_word.append(keyword)\n",
    "\n",
    "            # textrank 方法挖掘,每个文本返回最多top_K个结果\n",
    "            elif self.__exact == 'textrank':\n",
    "                for content in file.readlines()[:self.__num]:\n",
    "                    tags = jieba.analyse.textrank(content, topK=self.__topK)\n",
    "\n",
    "                    for keyword in tags:\n",
    "                        if keyword not in all_key_word:\n",
    "                            all_key_word.append(keyword)\n",
    "\n",
    "            # 按词频降序返回所有分词结果\n",
    "            elif self.__exact == 'tf':\n",
    "                keyword_dict = {}\n",
    "                for content in file.readlines()[:self.__num]:\n",
    "                    content = content.replace('\\n', '')\n",
    "                    tags = jieba.cut_for_search(content)\n",
    "\n",
    "                    for keyword in tags:\n",
    "                        if keyword in keyword_dict.keys():\n",
    "                            keyword_dict[keyword] += 1\n",
    "                        else:\n",
    "                            keyword_dict[keyword] = 1\n",
    "\n",
    "                # 按tf降序\n",
    "                temp = sorted(keyword_dict.items(), key=lambda item: item[1], reverse=True)\n",
    "                num = math.floor((self.__percentage / 100) * len(temp))\n",
    "                all_key_word = [v[0] for v in temp][:num]\n",
    "\n",
    "\n",
    "        return all_key_word\n",
    "\n",
    "\n",
    "    def save(self, file_name, all_key_word):\n",
    "        assert isinstance(file_name, str) and isinstance(all_key_word, list)\n",
    "        current_path = os.path.abspath(__file__)\n",
    "        # 获取当前文件的父目录\n",
    "        father_path = os.path.abspath(os.path.dirname(current_path) + os.path.sep + \".\")\n",
    "\n",
    "        save_path = father_path + '\\\\' + file_name\n",
    "\n",
    "        with open(save_path, 'w', encoding='utf-8') as file:\n",
    "            for key_word in all_key_word:\n",
    "                key_word = key_word + '\\n'\n",
    "                file.write(key_word)\n",
    "        print('save finish ! the save path:', save_path)\n",
    "\n",
    "if __name__=='__main__':\n",
    "\n",
    "    corpus_file_name = 'text2.txt'\n",
    "    idf_file_name = 'text_idf.txt'\n",
    "    stop_word_file_name = 'stopword.txt'\n",
    "\n",
    "    A = Key_word_exact()\n",
    "    A.set_corpus_file_name(corpus_file_name)\n",
    "    A.set_idf_file_name(idf_file_name)\n",
    "    A.set_stop_word_file_name(stop_word_file_name)\n",
    "    A.set_special_list()\n",
    "\n",
    "    A.set_topK(5)\n",
    "\n",
    "    #默认10000行\n",
    "    A.set_num()\n",
    "\n",
    "    A.set_exact('textrank')\n",
    "    textrank = A.word_exact()\n",
    "    A.save('textrank.txt', textrank)\n",
    "    print('textrank : ', textrank)\n",
    "\n",
    "    A.set_exact('tfidf')\n",
    "    tfidf = A.word_exact()\n",
    "    A.save('tfidf.txt', tfidf)\n",
    "    print('tfidf :', tfidf)\n",
    "\n",
    "    A.set_percentage(100)\n",
    "    A.set_exact('tf')\n",
    "    tf = A.word_exact()\n",
    "    A.save('tf1.txt', tf)\n",
    "    print('tf :', tf)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

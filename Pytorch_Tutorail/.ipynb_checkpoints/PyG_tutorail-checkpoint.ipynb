{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 一．PyG简介（PyG 1.3.2）\n",
    "1. PyG为用户提供通用的MessagePassing接口，以便对新的研究想法进行快速干净的原型制作。此外，几乎所有近期提出的邻域聚合函数都适用于此接口，其中包括PyG已经集成的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.torch_geometric.data\n",
    "### a.图数据转换\n",
    "<img src=\"pic/PYG1.png\" width=\"350\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 4], x=[3, 1])\n",
      "Data(edge_index=[2, 4], x=[3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "#无向图表达时，两个节点之间的一条边需要用两个tuple表示\n",
    "\n",
    "#边表达1：\n",
    "#每个list代表一条有向边，list第一元素是起始节点，第二个元素是终止节点\n",
    "edges1 = [[0,1],[1,0],[1,2],[2,1]]\n",
    "edge_index1 = torch.tensor(edges1, dtype = torch.long)#先转化为tensor\n",
    "\n",
    "#边表达2：\n",
    "#两个list，第一个list存储起始节点，第二个list存储终止节点\n",
    "edges2 = [[0, 1, 1, 2], [1, 0, 2, 1]]\n",
    "edge_index2 = torch.tensor(edges2, dtype = torch.long)\n",
    "\n",
    "node_features = [[-1], [0], [1]]\n",
    "x = torch.tensor(node_features, dtype = torch.float)\n",
    "\n",
    "data1 = Data(x=x, edge_index = edge_index1.t().contiguous())#转化为PyG DATA对象\n",
    "data2 = Data(x=x, edge_index = edge_index2)\n",
    "\n",
    "print(data1)\n",
    "print(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.图数据的属性查看"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "查看data属性: ['x', 'edge_index']\n",
      "查看节点特征: tensor([[-1.],\n",
      "        [ 0.],\n",
      "        [ 1.]])\n",
      "edge_index found in data\n",
      "x found in data\n",
      "查看节点数: 3\n",
      "查看边数 4\n",
      "查看节点特征维度: 1\n",
      "查看是否包含独立节点: False\n",
      "查看是否包含节点自环: False\n",
      "查看是否为有向图: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndata所有方法可以在以下链接查看:\\nhttps://pytorch-geometric.readthedocs.io/en/1.3.2/modules/data.html#torch_geometric.data.Data\\n'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"查看data属性:\",data1.keys)\n",
    "\n",
    "print(\"查看节点特征:\",data1['x'])\n",
    "\n",
    "for key, item in data1:\n",
    "    print(\"{} found in data\".format(key))\n",
    "    \n",
    "'edge_attr' in data1\n",
    " \n",
    "print(\"查看节点数:\",data1.num_nodes)\n",
    "\n",
    "print(\"查看边数\",data1.num_edges)\n",
    "\n",
    "print(\"查看节点特征维度:\", data1.num_node_features)\n",
    "\n",
    "print(\"查看是否包含独立节点:\", data1.contains_isolated_nodes())\n",
    "\n",
    "print(\"查看是否包含节点自环:\", data1.contains_self_loops())\n",
    "\n",
    "print(\"查看是否为有向图:\", data1.is_directed())\n",
    "\n",
    "'''\n",
    "data所有方法可以在以下链接查看:\n",
    "https://pytorch-geometric.readthedocs.io/en/1.3.2/modules/data.html#torch_geometric.data.Data\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.torch_geometric.datasets(公共基准数据集)\n",
    "<img src=\"pic/PYG2.png\" width=\"450\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.TUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图数据个数: 600\n",
      "数据种类: 6\n",
      "节点特征数: 3\n",
      "第一张图数据信息: Data(edge_index=[2, 168], x=[37, 3], y=[1]) 37个节点，每个节点3维，168/2=84条边，一个图标签\n",
      "训练图数据规模: ENZYMES(540)\n",
      "测试图数据规模: ENZYMES(60)\n",
      "打乱数据集dataset.shuffle(): ENZYMES(600)\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "dataset = TUDataset(root = \"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ENZYMES\", \n",
    "                    name = 'ENZYMES')\n",
    "\n",
    "print(\"图数据个数:\",len(dataset))\n",
    "print(\"数据种类:\",dataset.num_classes)\n",
    "print(\"节点特征数:\",dataset.num_node_features)\n",
    "\n",
    "data = dataset[0]\n",
    "print(\"第一张图数据信息:\",data,\"37个节点，每个节点3维，168/2=84条边，一个图标签\")\n",
    "#图数据分割\n",
    "train_dataset = dataset[:540]\n",
    "test_dataset = dataset[540:]\n",
    "print(\"训练图数据规模:\",train_dataset)\n",
    "print(\"测试图数据规模:\",test_dataset)\n",
    "print(\"打乱数据集dataset.shuffle():\",dataset.shuffle())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.Citeseer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图数据个数: 1\n",
      "数据种类: 6\n",
      "节点特征维度: 3703\n",
      "图属性: Data(edge_index=[2, 9104], test_mask=[3327], train_mask=[3327], val_mask=[3327], x=[3327, 3703], y=[3327])\n",
      "data.train_mask: tensor([ True,  True,  True,  ..., False, False, False])\n",
      "data.train_mask个数: 120\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root=\"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/Citeseer\", \n",
    "                    name = \"Citeseer\")\n",
    "\n",
    "print(\"图数据个数:\", len(dataset))\n",
    "print(\"数据种类:\",dataset.num_classes)\n",
    "print(\"节点特征维度:\",dataset.num_node_features)\n",
    "data = dataset[0]\n",
    "print(\"图属性:\",data)\n",
    "print(\"data.train_mask:\",data.train_mask)\n",
    "print(\"data.train_mask个数:\",data.train_mask.sum().item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Mini-batches\n",
    "### a.torch_geometric.data.DataLoader\n",
    "<img src=\"pic/PYG3.png\" width=\"450\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一个batch属性: Batch(batch=[1042], edge_index=[2, 4048], x=[1042, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[988], edge_index=[2, 3914], x=[988, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[893], edge_index=[2, 3536], x=[893, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[907], edge_index=[2, 3550], x=[907, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1079], edge_index=[2, 4142], x=[1079, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[928], edge_index=[2, 3668], x=[928, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1036], edge_index=[2, 3948], x=[1036, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1230], edge_index=[2, 4568], x=[1230, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1125], edge_index=[2, 4306], x=[1125, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1070], edge_index=[2, 4130], x=[1070, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1096], edge_index=[2, 3910], x=[1096, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[953], edge_index=[2, 3694], x=[953, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1035], edge_index=[2, 3830], x=[1035, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1028], edge_index=[2, 3916], x=[1028, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1148], edge_index=[2, 4538], x=[1148, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1040], edge_index=[2, 4044], x=[1040, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1179], edge_index=[2, 3862], x=[1179, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[1018], edge_index=[2, 3904], x=[1018, 21], y=[32])\n",
      "一个batch包含的图数据量: 32\n",
      "一个batch属性: Batch(batch=[785], edge_index=[2, 3056], x=[785, 21], y=[24])\n",
      "一个batch包含的图数据量: 24\n",
      "tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "         1,  1,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,  2,\n",
      "         2,  2,  2,  2,  2,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "         3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,\n",
      "         4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,\n",
      "         5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,\n",
      "         6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "         7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "         8,  8,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
      "         9,  9,  9,  9,  9,  9,  9,  9,  9,  9, 10, 10, 10, 10, 10, 10, 10, 10,\n",
      "        10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11,\n",
      "        11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "        12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13, 13,\n",
      "        13, 13, 13, 13, 13, 13, 13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,\n",
      "        14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 15, 15, 15, 15, 15, 15, 15,\n",
      "        15, 15, 15, 15, 15, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16,\n",
      "        16, 16, 16, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17,\n",
      "        17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 17, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18,\n",
      "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19, 19,\n",
      "        19, 19, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20,\n",
      "        20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21,\n",
      "        21, 22, 22, 22, 22, 22, 22, 22, 22, 22, 22, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23,\n",
      "        23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23])\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = dataset = TUDataset(root = \"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ENZYMES\", \n",
    "                              name = 'ENZYMES',\n",
    "                              use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size = 32, shuffle=True)\n",
    "#loader = DataLoader(dataset, batch_size = 32)\n",
    "\n",
    "for batch in loader:\n",
    "    print(\"一个batch属性:\",batch)\n",
    "    print(\"一个batch包含的图数据量:\",batch.num_graphs)\n",
    "\n",
    "print(batch.batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.batch的含义：\n",
    "<img src=\"pic/PYG4.png\" width=\"800\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.torch_scatter.scatter_mean\n",
    "<img src=\"pic/PYG5.png\" width=\"800\"/> \n",
    "关于PyTorch Scatter的用法:\n",
    "https://pytorch-scatter.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([24, 21])\n"
     ]
    }
   ],
   "source": [
    "from torch_scatter import scatter_mean\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "dataset = dataset = TUDataset(root = \"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ENZYMES\", \n",
    "                              name = 'ENZYMES',\n",
    "                              use_node_attr=True)\n",
    "loader = DataLoader(dataset, batch_size = 32, shuffle=True)\n",
    "\n",
    "for data in loader:\n",
    "    data\n",
    "#在一个batch中获取每一个图的节点特征矩平均向量，组成一个矩阵\n",
    "x = scatter_mean(data.x, data.batch, dim=0)\n",
    "print(x.size())                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Data Transforms(构建自己的数据集)\n",
    "<img src=\"pic/PYG6.png\" width=\"800\"/> \n",
    "将17000个3D点云图转化为2D图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jerry/anaconda3/lib/python3.8/site-packages/torch_geometric/data/dataset.py:89: UserWarning: The `pre_transform` argument differs from the one used in the pre-processed version of this dataset. If you really want to make use of another pre-processing technique, make sure to delete `/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ShapeNet/processed/processed` first.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D point 数据： Data(category=[1], edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "response = urllib.request.urlopen('https://www.python.org')\n",
    "\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ShapeNet',\n",
    "                   categories=['Airplane'])\n",
    "\n",
    "print(\"3D point 数据：\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/PYG7.png\" width=\"800\"/> \n",
    "使用KNN算法将3D点云图转化为2D图\n",
    "# 3D图转化为2D图需要第一在下载数据集时就处理，如果是数据集已经处理过，则3D图转2D图失败"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D point 数据 2D 化： Data(category=[1], edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "response = urllib.request.urlopen('https://www.python.org')\n",
    "\n",
    "# 使用KNN算法将3D云图转化为2D图\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ShapeNet',\n",
    "                   categories=['Airplane'],\n",
    "                  pre_transform = T.KNNGraph(k=6))\n",
    "\n",
    "print(\"3D point 数据 2D 化：\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"pic/PYG8.png\" width=\"800\"/> \n",
    "使用KNN算法将3D点云图转化为2D图，添加随机绕动\n",
    "# 3D图转化为2D图需要第一在下载数据集时就处理，如果是数据集已经处理过，则3D图转2D图失败"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D point 数据 2D 化,并随机化处理节点： Data(category=[1], edge_index=[2, 15108], pos=[2518, 3], y=[2518])\n"
     ]
    }
   ],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import ShapeNet\n",
    "\n",
    "dataset = ShapeNet(root='/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/ShapeNet',\n",
    "                   categories=['Airplane'],\n",
    "                  pre_transform = T.KNNGraph(k=6),\n",
    "                  transform=T.RandomTranslate(0.01))\n",
    "\n",
    "print(\"3D point 数据 2D 化,并随机化处理节点：\", dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.GCN构建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Citeseer()\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root=\"/home/jerry/local_git/notebook/Pytorch_Tutorail/PyG_Benchmark/Citeseer\", \n",
    "                    name = \"Citeseer\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6760\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "        \n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x , data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device =  torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = dataset[0].to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(),\n",
    "                             lr=0.01, \n",
    "                             weight_decay=5e-4)\n",
    "# 转换为训练模式\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_mask],data.y[data.train_mask])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# 转换为测试模式\n",
    "model.eval()\n",
    "_, pred = model(data).max(dim=1)\n",
    "correct = float (pred[data.test_mask].eq(data.y[data.test_mask]).sum().item())\n",
    "acc = correct / data.test_mask.sum().item()\n",
    "print('Accuracy: {:.4f}'.format(acc))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二．构建消息传递网络--针对空间域图卷积网络的设计范式(Message Passing Networks)\n",
    "![deque](pic/PYG9.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a.计算无向图中节点的度\n",
    "1. 图拓扑结构如下：\n",
    "\n",
    "<img src=\"pic/PYG10.png\" width=\"500\"/> \n",
    "\n",
    "2. degree方法:\n",
    "\n",
    "<img src=\"pic/PYG11.png\" width=\"500\"/> \n",
    "\n",
    "3. add_self_loop方法：\n",
    "\n",
    "<img src=\"pic/PYG12.png\" width=\"500\"/> \n",
    "\n",
    "4. torch.nn.Linear()方法：\n",
    "\n",
    "<img src=\"pic/PYG13.png\" width=\"500\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数节点数: 4\n",
      "原始数边数: 8\n",
      "原始数据: Data(edge_index=[2, 8], x=[4, 3])\n",
      "增加了自环边数据: (tensor([[0, 0, 0, 1, 2, 2, 3, 3, 0, 1, 2, 3],\n",
      "        [1, 2, 3, 0, 0, 3, 0, 2, 0, 1, 2, 3]]), None)\n",
      "row: tensor([0, 0, 0, 1, 2, 2, 3, 3, 0, 1, 2, 3])\n",
      "col: tensor([1, 2, 3, 0, 0, 3, 0, 2, 0, 1, 2, 3])\n",
      "计算增加自环图数据中节点度： tensor([4., 2., 3., 3.])\n",
      "计算原始图数据节点的度： tensor([3., 1., 2., 2.])\n",
      "计算图数据节点的度行向量:deg: tensor([3., 1., 2., 2.])\n",
      "计算１/sqrt(d_{i}): tensor([0.5774, 1.0000, 0.7071, 0.7071])\n",
      "row_: tensor([0, 0, 0, 1, 2, 2, 3, 3])\n",
      "col_: tensor([1, 2, 3, 0, 0, 3, 0, 2])\n",
      "deg_inv_sqrt[row_]: tensor([0.5774, 0.5774, 0.5774, 1.0000, 0.7071, 0.7071, 0.7071, 0.7071])\n",
      "deg_inv_sqrt[col_]: tensor([1.0000, 0.7071, 0.7071, 0.5774, 0.5774, 0.7071, 0.5774, 0.7071])\n",
      "norm: tensor([0.5774, 0.4082, 0.4082, 0.5774, 0.4082, 0.5000, 0.4082, 0.5000])\n",
      "将行向量norm变为列向量norm.view(-1,1): tensor([[0.5774],\n",
      "        [0.4082],\n",
      "        [0.4082],\n",
      "        [0.5774],\n",
      "        [0.4082],\n",
      "        [0.5000],\n",
      "        [0.4082],\n",
      "        [0.5000]])\n",
      "x_t.shape: torch.Size([4, 5])\n",
      "线性变换后的node_features_matrix: tensor([[-0.8991,  0.1697, -0.5391, -1.1535, -0.5061],\n",
      "        [-0.6310, -0.7987, -0.6464, -1.0534,  0.8562],\n",
      "        [-0.9641, -0.3788, -0.7748, -1.1118, -0.0575],\n",
      "        [-1.1591, -2.0241, -1.4820, -0.9868,  1.2882]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "#无向图表达时，两个节点之间的一条边需要用两个tuple表示\n",
    "\n",
    "#边表达2：\n",
    "#两个list，第一个list存储起始节点，第二个list存储终止节点\n",
    "edges = [[0, 0, 0, 1, 2, 2, 3, 3], [1, 2, 3, 0, 0, 3, 0, 2]]\n",
    "edge_index = torch.tensor(edges, dtype = torch.long)\n",
    "\n",
    "node_features = [[-1,1,2], [1,1,1], [0,1,2], [3,1,2]]\n",
    "x = torch.tensor(node_features, dtype = torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index = edge_index)\n",
    "\n",
    "print(\"原始数节点数:\",data.num_nodes)\n",
    "print(\"原始数边数:\",data.num_edges)\n",
    "\n",
    "print(\"原始数据:\",data)\n",
    "\n",
    "from torch_geometric.utils import add_self_loops,degree\n",
    "\n",
    "#给图数据的边增加自环边\n",
    "self_loop_edge= add_self_loops(data.edge_index, \n",
    "                               num_nodes=data.num_nodes)\n",
    "\n",
    "print(\"增加了自环边数据:\", self_loop_edge)\n",
    "\n",
    "row, col = self_loop_edge[0]\n",
    "\n",
    "print(\"row:\",row)\n",
    "print(\"col:\",col)\n",
    "\n",
    "print(\"计算增加自环图数据中节点度：\", degree(col))\n",
    "print(\"计算原始图数据节点的度：\",degree(data.edge_index[0],\n",
    "                            num_nodes=data.num_nodes))\n",
    "\n",
    "#对节点度进行运算操作：\n",
    "\n",
    "row_, col_ = data.edge_index\n",
    "# 计算图数据节点的度行向量\n",
    "\n",
    "deg = degree(row_)\n",
    "# 计算１/sqrt(d_{i})\n",
    "\n",
    "deg_inv_sqrt = deg.pow(-0.5)\n",
    "\n",
    "print(\"计算图数据节点的度行向量:deg:\",deg)\n",
    "print(\"计算１/sqrt(d_{i}):\",deg_inv_sqrt)\n",
    "\n",
    "print(\"row_:\",row_)\n",
    "print(\"col_:\",col_)\n",
    "\n",
    "norm = deg_inv_sqrt[row_]*deg_inv_sqrt[col_]\n",
    "print(\"deg_inv_sqrt[row_]:\",deg_inv_sqrt[row_])\n",
    "print(\"deg_inv_sqrt[col_]:\",deg_inv_sqrt[col_])\n",
    "print(\"norm:\",norm)\n",
    "print(\"将行向量norm变为列向量norm.view(-1,1):\",norm.view(-1,1))\n",
    "\n",
    "# 构建带学习参数的线性变换\n",
    "input_features = 3 # 节点的特征维度\n",
    "output_features = 5\n",
    "linear_transform = torch.nn.Linear(input_features, output_features)\n",
    "\n",
    "x_t = linear_transform(data.x)\n",
    "\n",
    "print(\"x_t.shape:\",x_t.shape)\n",
    "\n",
    "print(\"线性变换后的node_features_matrix:\",x_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b.使用消息传递网络构建GCN前向传播过程\n",
    "### MessagePassing类中函数自动调用逻辑链：self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)——>message(self, x_j, edge_index, size)——>update(self, aggr_out)\n",
    "1.　输入的拓扑图结构:\n",
    "<img src=\"pic/PYG10.png\" width=\"500\"/> \n",
    "2. 输入x_features_matrix的维度自动转换： \n",
    "\n",
    "2.1. 经过线性变换后的x,shape=[4, 5]\n",
    "<img src=\"pic/PYG14_1.png\" width=\"1500\"/> \n",
    "<img src=\"pic/PYG14_2.png\" width=\"1000\"/> \n",
    "2.2. 调用self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)——>message(self, x_j, edge_index, size)\n",
    "\n",
    "x_j自动将x从shape[N, out_channels]对应 edge_index起始节点列表节点信息转换为shape[E,out_channels ]\n",
    "\n",
    "2.3.x_j shape:\n",
    "<img src=\"pic/PYG16.png\" width=\"500\"/> \n",
    "2.4.edge_index:\n",
    "<img src=\"pic/PYG15.png\" width=\"1000\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "class GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation.\n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "\n",
    "        # Step 3-5: Start propagating messages.\n",
    "        return self.propagate(edge_index, size=(x.size(0), x.size(0)), x=x)\n",
    "        \n",
    "    def message(self, x_j, edge_index, size):\n",
    "        # x_j自动将x从shape[N, out_channels]对应 edge_index起始节点列表节点信息转换为shape[E,out_channels ]\n",
    "        # x_j has shape [E, out_channels]\n",
    "\n",
    "        # Step 3: Normalize node features.\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, size[0], dtype=x_j.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        # aggr_out has shape [N, out_channels]\n",
    "\n",
    "        # Step 5: Return new node embeddings.\n",
    "        return aggr_out\n",
    "\n",
    "#data\n",
    "edges = [[0, 0, 0, 1, 2, 2, 3, 3], [1, 2, 3, 0, 0, 3, 0, 2]]\n",
    "edge_index = torch.tensor(edges, dtype = torch.long)\n",
    "\n",
    "node_features = [[-1, 1, 2], [1, 1, 1], [0, 1, 2], [3, 1, 2]]\n",
    "x = torch.tensor(node_features, dtype = torch.float)\n",
    "\n",
    "data = Data(x=x, edge_index = edge_index)\n",
    "\n",
    "x = data.x\n",
    "edge_index = data.edge_index\n",
    "\n",
    "conv = GCNConv(3, 5)\n",
    "x = conv(x, edge_index)\n",
    "print(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
